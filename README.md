# AgentLens ğŸ”

**Observability and Explainability for AI Agents**

AgentLens gives you full visibility into what your AI agents are doing, why they're doing it, and how much it costs. Think of it as Datadog meets Chain-of-Thought â€” for agents.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     HTTP POST      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     SQLite      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Your Agent  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  AgentLens API  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚    DB    â”‚
â”‚  + SDK       â”‚    /events         â”‚  (Express.js)   â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚ REST API
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   Dashboard      â”‚
                                    â”‚  (HTML/CSS/JS)   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

| Component | Directory | Tech |
|-----------|-----------|------|
| Python SDK | `sdk/` | Python 3.9+, Pydantic, httpx |
| Backend API | `backend/` | Node.js, Express, better-sqlite3 |
| Dashboard | `dashboard/` | Vanilla HTML/CSS/JS |

## Quickstart

### 1. Start the Backend

```bash
cd backend
npm install
node seed.js      # Load demo data
node server.js    # Starts on http://localhost:3000
```

### 2. Open the Dashboard

```bash
# Served by the backend at:
open http://localhost:3000
```

### 3. Instrument Your Agent

```bash
cd sdk
pip install -e .
```

```python
import agentlens

agentlens.init(api_key="your-key", endpoint="http://localhost:3000")
session = agentlens.start_session(agent_name="my-agent")

# Automatic tracking with decorators
@agentlens.track_agent
def my_agent(prompt):
    response = call_llm(prompt)
    return response

# Or manual tracking
agentlens.track(
    event_type="llm_call",
    input_data={"prompt": "Hello"},
    output_data={"response": "Hi there!"},
    model="gpt-4",
    tokens_in=5,
    tokens_out=10,
)

# Get human-readable explanation of agent behavior
explanation = agentlens.explain()
print(explanation)

session.end()
```

### 4. Run the Demo

```bash
cd sdk/examples
python mock_agent.py
```

## Features

- ğŸ“Š **Session tracking** â€” Group agent actions into sessions with full traces
- ğŸ”§ **Tool call capture** â€” See every tool invocation with inputs/outputs
- ğŸ’° **Token usage** â€” Track costs across models and calls
- ğŸ§  **Decision traces** â€” Capture *why* an agent made each choice
- ğŸ“ˆ **Visual timeline** â€” See agent actions on an interactive timeline
- ğŸ’¡ **Explainability** â€” Human-readable summaries of agent behavior

## License

MIT â€” see [LICENSE](LICENSE)
